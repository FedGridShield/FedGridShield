# add all attack methods here

# Backdoor Attack (Targeted Model Poisoning Attack - "Described such as in the paper FLDetector")

## Constrain-and-Scale
We reference the code from [here](https://github.com/ebagdasa/backdoor_federated_learning).